# -*- coding: utf-8 -*-
"""Wordandsentencelabelcode.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AsK67tTEBWQl79_Nwtak4jkCpjGjY1kl
"""

#def multi_word_sentiment_evaluation(text_list: list)>str:



pip install transformers torch





from transformers import pipeline

sentiment_analysis = pipeline("sentiment-analysis")

#def multi_word_sentiment_evaluation(text_list: list)>str:
def multi_word_sentiment_evaluation(text):
  results=[]
  for entry in texts:
    text=entry['text']
    sentiment=sentiment_analysis(text)[0]
    results.append(f"{entry['id']}:{sentiment['label']}")
  return results


texts = [
    {"id": 1, "text": "I love this product! It works great."},
    {"id": 2, "text": "This is the worst experience I've ever had."},
    {"id": 3, "text": "The movie was okay, not the best but not the worst."},
    {"id": 4, "text": "Absolutely fantastic service and friendly staff."},
    {"id": 5, "text": "I'm disappointed with the quality."}
]
results= multi_word_sentiment_evaluation(texts)
for result in results:
  print(result)

def multi_word_sentiment_evaluation(texts):
    """
    Analyzes the overall sentiment of multiple text entries and returns results with their IDs.

    Args:
        texts (list of dict): A list where each dictionary contains:
            - 'id' (int): A unique identifier for the text entry.
            - 'text' (str): The sentence/phrase to analyze.

    Returns:
        list of str: A list of formatted strings showing each entry's sentiment in the format:
            "ID: SENTIMENT_LABEL" (e.g., "1: POSITIVE").

    Example:
        >>> texts = [{"id": 1, "text": "I love this!"}]
        >>> multi_word_sentiment_evaluation(texts)
        ["1: POSITIVE"]
    """
    results = []  # Stores the output (ID + sentiment pairs)

    for entry in texts:
        text = entry['text']  # Extract the text (e.g., "I love this product!")
        sentiment = sentiment_analysis(text)[0]  # Get sentiment (assumes this function exists)
        results.append(f"{entry['id']}:{sentiment['label']}")  # Format: "ID: LABEL"

    return results


# Example usage
if __name__ == "__main__":
    # Sample input data: List of texts with IDs
    texts = [
        {"id": 1, "text": "I love this product! It works great."},
        {"id": 2, "text": "This is the worst experience I've ever had."},
        {"id": 3, "text": "The movie was okay, not the best but not the worst."},
        {"id": 4, "text": "Absolutely fantastic service and friendly staff."},
        {"id": 5, "text": "I'm disappointed with the quality."}
    ]

    # Get sentiment results for all texts
    results = multi_word_sentiment_evaluation(texts)

    # Print results line by line
    for result in results:
        print(result)

def word_level_sentiment(texts):

  result=[]
  for entry in texts:
    word=entry['text']
    words= word.split()
    for word in words:
      sentiment=sentiment_analysis(word)[0]
      result.append(f"{word}:{sentiment['label']}")
  return result

text = [
    {"id": 1, "text": "I love this product! It works great."},
    {"id": 2, "text": "This is the worst experience I've ever had."},
    {"id": 3, "text": "The movie was okay, not the best but not the worst."},
    {"id": 4, "text": "Absolutely fantastic service and friendly staff."},
    {"id": 5, "text": "I'm disappointed with the quality."}
]
results=word_level_sentiment(text)
for result in results:
  print(result)



def word_level_sentiment(texts):
    """
    Analyzes the sentiment of each word in a list of text entries and returns results with their IDs.

    Args:
        texts (list of dict): A list where each dictionary contains:
            - 'id' (int): A unique identifier for the text entry.
            - 'text' (str): The sentence/phrase to analyze.

    Returns:
        list of str: A list of formatted strings showing each word's sentiment in the format:
            "{id} - {word}: {sentiment_label}"

    Example:
        >>> texts = [{"id": 1, "text": "I love this!"}]
        >>> word_level_sentiment(texts)
        ["1 - I: NEUTRAL", "1 - love: POSITIVE", "1 - this!: NEUTRAL"]
    """
    results = []  # Stores the output (formatted word sentiments)

    for entry in texts:
        text = entry['text']  # Extract the text string (e.g., "I love this")
        words = text.split()  # Split into individual words ["I", "love", "this"]

        for word in words:
            # Get sentiment for the current word (assumes sentiment_analysis is defined)
            sentiment = sentiment_analysis(word)[0]
            # Format: "ID - word: SENTIMENT" (e.g., "1 - love: POSITIVE")
            results.append(f"{entry['id']} - {word}: {sentiment['label']}")

    return results


# Example usage
if __name__ == "__main__":
    # Sample input: List of texts with IDs
    text_data = [
        {"id": 1, "text": "I love this product! It works great."},
        {"id": 2, "text": "This is the worst experience I've ever had."},
        {"id": 3, "text": "The movie was okay, not the best but not the worst."},
        {"id": 4, "text": "Absolutely fantastic service and friendly staff."},
        {"id": 5, "text": "I'm disappointed with the quality."}
    ]

    # Analyze word-level sentiment
    results = word_level_sentiment(text_data)

    # Print results
    for result in results:
        print(result)

def analyze_sentiment(texts, granularity="sentence"):
    """
    Analyzes sentiment at either sentence-level or word-level (or both).

    Args:
        texts (list of dict): List of entries with 'id' and 'text'.
        granularity (str): Options:
            - "sentence": Returns overall sentiment per text (default).
            - "word": Returns sentiment per word.
            - "both": Returns both sentence and word-level results.

    Returns:
        list of str: Formatted results based on granularity.

    Example:
        >>> analyze_sentiment(texts, granularity="both")
        ["1 (Sentence): POSITIVE", "1 - love: POSITIVE", ...]
    """
    results = []

    for entry in texts:
        text = entry['text']
        sentence_sentiment = sentiment_analysis(text)[0]  # Sentence-level analysis

        if granularity == "sentence":
            results.append(f"{entry['id']} (Sentence): {sentence_sentiment['label']}")

        elif granularity == "word":
            words = text.split()
            for word in words:
                word_sentiment = sentiment_analysis(word)[0]  # Word-level analysis
                results.append(f"{entry['id']} - {word}: {word_sentiment['label']}")

        elif granularity == "both":
            results.append(f"{entry['id']} (Sentence): {sentence_sentiment['label']}")
            words = text.split()
            for word in words:
                word_sentiment = sentiment_analysis(word)[0]
                results.append(f"{entry['id']} - {word}: {word_sentiment['label']}")

    return results


# Example Usage
texts = [{"id": 1, "text": "I love this product! It works great."},
        {"id": 2, "text": "This is the worst experience I've ever had."},
        {"id": 3, "text": "The movie was okay, not the best but not the worst."},
        {"id": 4, "text": "Absolutely fantastic service and friendly staff."},
        {"id": 5, "text": "I'm disappointed with the quality."}
]

# Choose granularity: "sentence", "word", or "both"
results = analyze_sentiment(texts, granularity="both")

for result in results:
    print(result)